{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## annotated transformer(from Harvard NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "query = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[3,2,3],[3,2,1],[1,2,3]])\n",
    "key = torch.FloatTensor([[2.2,4,3],[6,9,1],[8,2,9],[1,4,5],[2,4,5],[3,2,9]])\n",
    "value = torch.FloatTensor([[1,1,1],[1,1,1],[1,1,1],[1,1,1],[1,1,1],[4,8,9]])\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query,key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        # masked_fill(mask,value)\n",
    "        # fills elements of self tensor with value where mask is one\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores,dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "        \n",
    "    # value에 확률값 곱하고 더한 벡터, 확률값\n",
    "    return torch.matmul(p_attn,value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1582, 1.3692, 1.4219],\n",
       "         [1.0000, 1.0001, 1.0001],\n",
       "         [1.0000, 1.0000, 1.0000],\n",
       "         [1.0005, 1.0012, 1.0014],\n",
       "         [1.0003, 1.0006, 1.0007],\n",
       "         [1.1582, 1.3692, 1.4219]]),\n",
       " tensor([[1.0261e-05, 9.2672e-04, 9.4587e-01, 1.6396e-04, 2.9206e-04, 5.2739e-02],\n",
       "         [4.6087e-13, 5.4256e-06, 9.9998e-01, 2.9438e-11, 2.9640e-10, 9.6648e-06],\n",
       "         [1.9581e-20, 3.0047e-08, 1.0000e+00, 4.9996e-18, 2.8452e-16, 1.6753e-09],\n",
       "         [1.3386e-08, 9.7284e-05, 9.9973e-01, 5.3508e-08, 3.0244e-07, 1.7329e-04],\n",
       "         [6.8323e-06, 4.9994e-01, 4.9994e-01, 2.7126e-06, 1.5332e-05, 8.6660e-05],\n",
       "         [1.0261e-05, 9.2672e-04, 9.4587e-01, 1.6396e-04, 2.9206e-04, 5.2739e-02]]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # linear projections in batch from d_model\n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
    "                            for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # apply attention on all the projected vectors in batch\n",
    "        x, self.attn = attention(query, key, value, mask = mask,\n",
    "                                dropout = self.dropout)\n",
    " \n",
    "        # concat using a view and apply a final linear\n",
    "        x = x.transpose(1,2).contiguous().view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25, 25, 14, 14],\n",
       "        [25, 25, 14, 14],\n",
       "        [25, 25, 14, 14],\n",
       "        [25, 25, 14, 14]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [   1],\n",
       "        [   2],\n",
       "        ...,\n",
       "        [4997],\n",
       "        [4998],\n",
       "        [4999]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(0,5000).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "a = torch.exp(torch.arange(0, 512, 2, dtype = torch.float32) * -(math.log(10000.0) / 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype = torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype = torch.float32) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-9b6d8737c180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPositionalEncoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dim %d\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Variable' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "pe = PositionalEncoding(20, 0)\n",
    "y = pe.forward(Variable(torch.zeros(1, 100, 20)))\n",
    "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
    "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "attn_shape = (1,512,512)\n",
    "subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "a = torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def subsequent_mask(size):\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(20)[0])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 6],\n",
       "        [2, 2],\n",
       "        [3, 5]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[6,2,5]])\n",
    "a.transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0, 512, 2) * -(math.log(10000.0) / 512)\n",
    "b = torch.arange(0, 512, 2, dtype=torch.float32) * -(math.log(10000.0) / 512)\n",
    "\n",
    "print(b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "position = torch.arange(0, 5000).unsqueeze(1)\n",
    "print(position.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "trg = torch.tensor([[1,2,3,4,5],[6,3,6,3,7],[2,8,2,3,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4, 5],\n",
       "        [3, 6, 3, 7],\n",
       "        [8, 2, 3, 7]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg[:,:-1]\n",
    "trg[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
